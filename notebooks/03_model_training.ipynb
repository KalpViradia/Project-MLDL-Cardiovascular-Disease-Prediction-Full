{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c68a3f8c-de24-4611-93b6-2c22c6f0562a",
   "metadata": {},
   "source": [
    "# 03 \u2013 Model Training & Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fb977c3-c63b-40de-b3fd-5dd06fd69407",
   "metadata": {},
   "source": [
    "## 1. Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fc12223-b5c1-4e39-a9b1-11ace129c86c",
   "metadata": {},
   "source": [
    "In this notebook, we train machine learning models for the\n",
    "Cardiovascular Disease Risk Prediction System."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c67f7f68-d3f9-44c3-8ba0-8dc3fca374c1",
   "metadata": {},
   "source": [
    "## 2. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3e87e01-918b-486f-a341-34f71c3d9c84",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import joblib\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report, roc_auc_score, roc_curve\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ade80bca-0187-412e-8d14-80f4433f1369",
   "metadata": {},
   "source": [
    "## 3. Load Preprocessed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8098d148-b27d-423d-9bf5-c65428e37ebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"../data/processed/cleaned_data.csv\")\n",
    "\n",
    "X = data.drop(columns = [\"cardio\", \"id\"])\n",
    "y = data[\"cardio\"].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42, stratify = y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c07aca8-65b4-4e26-9d44-0edc052dff84",
   "metadata": {},
   "source": [
    "# PART A \u2014 Model From Scratch (No Libraries)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15c9a3dd-72e1-4293-845a-584d22250f2b",
   "metadata": {},
   "source": [
    "## 4. Build Logistic Regression From Scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd7b6456-4c78-4214-87e1-4bf02c90216b",
   "metadata": {},
   "source": [
    "### 4.1 Sigmoid Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caa7f0b6-4f2e-4ba6-abb6-3d7f4d40ec51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RuntimeWarning: overflow encountered in exp\n",
    "# def sigmoid(z):\n",
    "#     return 1 / (1 + np.exp(-z))\n",
    "\n",
    "def sigmoid(z):\n",
    "    z = np.clip(z, -500, 500)      # Prevent overflow\n",
    "    return 1 / (1 + np.exp(-z))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e048beff-c9f1-4533-8fdd-c017831f9a38",
   "metadata": {},
   "source": [
    "### 4.2 Custom Logistic Regression Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "157d1732-784d-4291-9b41-11bc79f5a17f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomLogisticRegression:\n",
    "    def __init__(self, lr = 0.01, epochs = 1000):\n",
    "        # lr: learning rate \u2014 controls how big the weight updates are.\n",
    "        # epochs: number of times the algorithm loops through the entire training set.\n",
    "        self.lr = lr\n",
    "        self.epochs = epochs\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        # Add a bias term (column of 1s) to the feature matrix.\n",
    "        X = np.insert(X, 0, 1, axis = 1)\n",
    "        \n",
    "        # Initialize weights to zeros (one weight per feature + bias).\n",
    "        self.weights = np.zeros(X.shape[1])\n",
    "        \n",
    "        # Gradient descent loop for the specified number of epochs.\n",
    "        for _ in range(self.epochs):\n",
    "            # Linear combination of inputs and weights.\n",
    "            z = np.dot(X, self.weights)\n",
    "            \n",
    "            # Apply the sigmoid function to get probabilities.\n",
    "            y_pred = sigmoid(z)\n",
    "            \n",
    "            # Compute the gradient of the loss with respect to the weights.\n",
    "            gradient = np.dot(X.T, (y_pred - y)) / y.size\n",
    "            \n",
    "            # Update weights using gradient descent.\n",
    "            self.weights -= self.lr * gradient\n",
    "    \n",
    "    def predict(self, X):\n",
    "        # Add the bias term to the input data (same as during training).\n",
    "        X = np.insert(X, 0, 1, axis = 1)\n",
    "        \n",
    "        # Compute probabilities using the sigmoid of the linear combination.\n",
    "        probabilities = sigmoid(np.dot(X, self.weights))\n",
    "        \n",
    "        # Convert probabilities to binary predictions (0 or 1) using threshold 0.5.\n",
    "        return (probabilities >= 0.5).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b21562a5-c8f8-49d8-9329-e66c70a22809",
   "metadata": {},
   "source": [
    "## 5. Train Custom Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b86dbf16-dad3-4fa9-90d4-c8ee838f0521",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_np = X_train.values\n",
    "X_test_np = X_test.values\n",
    "\n",
    "model_scratch = CustomLogisticRegression(lr = 0.01, epochs = 1500)\n",
    "model_scratch.fit(X_train_np, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d533ddf3-c8e9-4f10-b991-e138fc806c73",
   "metadata": {},
   "source": [
    "## 6. Evaluate Custom Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9433dd8-c7f6-4aa3-aab0-b5f0e9b9d9e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_scratch = model_scratch.predict(X_test_np)\n",
    "\n",
    "# Print the accuracy of the model: \n",
    "# Accuracy = (Number of correct predictions) / (Total predictions)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_scratch))\n",
    "\n",
    "# Print the precision of the model:\n",
    "# Precision = True Positives / (True Positives + False Positives)\n",
    "# Measures how many predicted positives are actually positive.\n",
    "print(\"Precision:\", precision_score(y_test, y_pred_scratch))\n",
    "\n",
    "# Print the recall of the model:\n",
    "# Recall = True Positives / (True Positives + False Negatives)\n",
    "# Measures how many actual positives were correctly predicted.\n",
    "print(\"Recall:\", recall_score(y_test, y_pred_scratch))\n",
    "\n",
    "# Print the F1 score of the model:\n",
    "# F1 Score = 2 * (Precision * Recall) / (Precision + Recall)\n",
    "# Harmonic mean of precision and recall; balances both metrics.\n",
    "print(\"F1 Score:\", f1_score(y_test, y_pred_scratch))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3936b874-7832-48a2-8246-ba81e2d79a58",
   "metadata": {},
   "source": [
    "# PART B \u2014 Random Forest (Best Performing Model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "439f56ff-0349-4d8e-815e-79d8e1778d5f",
   "metadata": {},
   "source": [
    "## 7. Feature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac4e7a37-1acc-4159-9b12-eb9e87fe747d",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cols = ['height', 'weight', 'ap_hi', 'ap_lo', 'bmi', 'age_years']\n",
    "\n",
    "X_train_scaled = X_train.copy()\n",
    "X_test_scaled  = X_test.copy()\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled[num_cols] = scaler.fit_transform(X_train[num_cols])\n",
    "X_test_scaled[num_cols]  = scaler.transform(X_test[num_cols])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c0a997b-a807-46f3-9b93-115b5c3276f8",
   "metadata": {},
   "source": [
    "## 8. Train Random Forest Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0c9dd46-172a-4fe9-b528-7f69eccd7352",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Random Forest with RandomizedSearchCV\n",
    "rf = RandomForestClassifier(random_state=42, class_weight=\"balanced\")\n",
    "\n",
    "param_dist = {\n",
    "    'n_estimators': [100, 200, 300, 500],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=rf,\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=10,\n",
    "    cv=3,\n",
    "    scoring='accuracy',\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"Starting Hyperparameter Tuning...\")\n",
    "# Use scaled data!\n",
    "random_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Get best model\n",
    "rf = random_search.best_estimator_\n",
    "\n",
    "print(f\"Best Parameters: {random_search.best_params_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98bc55fa-4fca-4c51-909a-b18571d61df3",
   "metadata": {},
   "source": [
    "## 9. Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc5e4d8a-aa16-465a-bbf7-0bc87288f296",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_rf = rf.predict(X_test_scaled)\n",
    "y_proba_rf = rf.predict_proba(X_test_scaled)[:, 1] # proba is probabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "444aa202-eeb7-45fa-8759-69e45dea8e1f",
   "metadata": {},
   "source": [
    "## 10. Evaluation Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c7661ae-46b5-4f60-bf8d-3c004c9c15b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy :\", accuracy_score(y_test, y_pred_rf))\n",
    "print(\"Precision:\", precision_score(y_test, y_pred_rf))\n",
    "print(\"Recall   :\", recall_score(y_test, y_pred_rf))\n",
    "print(\"F1 Score :\", f1_score(y_test, y_pred_rf))\n",
    "\n",
    "# zero_division = 0 prevents warnings if some classes have no predicted samples (optional to add in classification_report)\n",
    "print(\"\\nClassification Report:\\n\")\n",
    "print(classification_report(y_test, y_pred_rf))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f73a40c8-d20e-4f5b-b837-79db58c280ef",
   "metadata": {},
   "source": [
    "## 11. Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e80867c3-6ca9-4857-9014-7f511b9881b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test, y_pred_rf)\n",
    "\n",
    "plt.figure(figsize = (6, 4))\n",
    "sns.heatmap(cm, annot = True, fmt = 'd', cmap = 'Blues') # fmt is format of the annotations\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eed040b1-468d-4e85-97c6-9b56851ba3b3",
   "metadata": {},
   "source": [
    "## 12. ROC\u2013AUC Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c104a379-e490-4ffd-9acf-cba230f847eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, thresholds = roc_curve(y_test, y_proba_rf)\n",
    "\n",
    "plt.figure(figsize = (6, 4))\n",
    "plt.plot(fpr, tpr, label = \"Random Forest\")\n",
    "plt.plot([0, 1], [0, 1], linestyle = '--', color = 'gray')\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"Roc Curve - Random Forest\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "print(\"ROC AUC Score:\", roc_auc_score(y_test, y_proba_rf))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c628907-0545-42b6-9ae4-f95e84e095c3",
   "metadata": {},
   "source": [
    "## 13. Best Classification Threshold (Youden\u2019s J)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "237f03a2-7210-4ece-bae6-f507e7007b25",
   "metadata": {},
   "outputs": [],
   "source": [
    "j_scores = tpr - fpr\n",
    "best_idx = np.argmax(j_scores)\n",
    "best_threshold = thresholds[best_idx]\n",
    "\n",
    "print(f\"Best threshold: {best_threshold:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc4f9528-b577-4a50-b015-697bbefdcdf3",
   "metadata": {},
   "source": [
    "## 14. Save Model, Scaler, Threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0939ce0-fcc2-4baa-8833-b33a764c5ae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(rf, \"../models/best_model.pkl\")\n",
    "joblib.dump(scaler, \"../models/scaler.pkl\")\n",
    "joblib.dump(best_threshold, \"../models/threshold.pkl\")\n",
    "\n",
    "print(\"Model, scaler, and threshold saved successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6827e0b9-b6e0-46ad-978a-14228a4fa56f",
   "metadata": {},
   "source": [
    "## 15. Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98d0f726-cea9-4cbb-8522-0c9fc37a66dc",
   "metadata": {},
   "source": [
    "### Model Training Completed\n",
    "\n",
    "- Logistic Regression from scratch implemented  \n",
    "- Random Forest trained using scaled features  \n",
    "- Evaluated using Accuracy, Precision, Recall, F1  \n",
    "- Confusion Matrix and ROC\u2013AUC included  \n",
    "- Best threshold identified using Youden\u2019s J  \n",
    "- Saved:\n",
    "  - best_model.pkl\n",
    "  - scaler.pkl\n",
    "  - threshold.pkl"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}